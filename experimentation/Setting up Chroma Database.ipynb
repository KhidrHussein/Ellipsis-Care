{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add OpenAI library\n",
    "import openai\n",
    "\n",
    "# Get Configuration Settings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API using Azure OpenAI\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "openai.api_base = os.getenv(\"ENDPOINT\")\n",
    "openai.api_type = \"azure\"  # Necessary for using the OpenAI library with Azure OpenAI\n",
    "openai.api_version = \"2024-02-01\"  # Latest / target version of the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings, AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Settings\n",
    "model_deployment = \"text-embedding-ada-002\"\n",
    "# SDK calls this \"engine\", but naming it \"deployment_name\" for clarity\n",
    "\n",
    "model_name = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_version = os.getenv(\"OPENAI_API_VERSION\"), openai_api_key = os.getenv(\"API_KEY\"),\n",
    "    openai_api_base = os.getenv(\"ENDPOINT\"), openai_api_type = \"azure\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store_ellipsis = Chroma(\n",
    "    collection_name=\"Ellipsis-Care-Docs\",\n",
    "    embedding_function=openai_embeddings,\n",
    "    persist_directory=\"/Users/mac/Documents/Ellipsis-Care/Ellipsis-Care-Chroma-Vector-DB\",  # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def upsert_pdf_content(file:str) -> Exception:\n",
    "        \"\"\"\n",
    "        This method is responsible for upserting PDF content.\n",
    "        It loads the PDF file, splits the content into chunks, and then upserts the chunks into VecDB.\n",
    "        \"\"\"\n",
    "        loader = PyPDFLoader(file)\n",
    "        data = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"])\n",
    "        docs = text_splitter.split_documents(data)\n",
    "        # print(docs)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def load_and_process_pdfs(pdf_folder_path):\n",
    "        \"\"\"\n",
    "        This method is responsible for upserting PDF content.\n",
    "        It loads the PDF file, splits the content into chunks, and then upserts the chunks into VecDB.\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for file in os.listdir(pdf_folder_path):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(pdf_folder_path, file)\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                documents.extend(loader.load())\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_folder_path =  \"/Users/mac/Documents/Ellipsis-Care/data\"\n",
    "splits = load_and_process_pdfs(pdf_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awareness for the problem of chronic diseases? Is it to build support for the development of an action framework to prevent and control chronic diseases? Is it to promote the already developed action framework to prevent and control chronic diseases? It is important to identify specifically a goal and objectives for the advocating campaign. Establish a clear long-term goal and SMART (specific, measurable, achievable, relevant and timely) objectives at the beginning of your advocacy work.   Step 2: Identify target audiences In advocacy work, the two main audiences will usually be decision-makers and influencers. The more specific you are in identifying the audience, the more effective your communications will be.   A. Potential decision-makers: B. Potential influencers: 1. Government (ministries and parliament): • presidents and prime ministers • health ministers and their deputies • budgetary decision makers (e.g. ministers of finance) • ministers of related sectors and their deputies\n"
     ]
    }
   ],
   "source": [
    "print(splits[30].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/mac/Documents/Ellipsis-Care/data/Action Framework for the Prevention and Control of Chronic Disease.pdf', 'page': 0}, page_content='1  Draft version 4, 3 August 2006.          WHO Action Framework  for the  Prevention and Control  of  Chronic Diseases    - Core package -')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(splits[i])\n",
    "#     print(i)\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuids = [str(uuid4()) for _ in range(len(splits))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2227"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uuid import uuid4\n",
    "# import time\n",
    "\n",
    "# delay = 70  # Delay in seconds between batches\n",
    "\n",
    "# for file in os.listdir(pdf_folder_path):\n",
    "#     if file.endswith(\".pdf\"):\n",
    "#         pdf_path = os.path.join(pdf_folder_path, file)\n",
    "#         docs = upsert_pdf_content(pdf_path)\n",
    "#         for chunk in docs:\n",
    "#             doc_id = str(uuid4())\n",
    "#             vector_store_ellipsis.add_documents(documents=[chunk], ids=[doc_id])\n",
    "#             time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 0 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 100 documents\n",
      "Upserting 200 documents\n",
      "Upserting 300 documents\n",
      "Upserting 400 documents\n",
      "Upserting 500 documents\n",
      "Upserting 600 documents\n",
      "Upserting 700 documents\n",
      "Upserting 800 documents\n",
      "Upserting 900 documents\n",
      "Upserting 1000 documents\n",
      "Upserting 1100 documents\n",
      "Upserting 1200 documents\n",
      "Upserting 1300 documents\n",
      "Upserting 1400 documents\n",
      "Upserting 1500 documents\n",
      "Upserting 1600 documents\n",
      "Upserting 1700 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_community.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 1800 documents\n",
      "Upserting 1900 documents\n",
      "Upserting 2000 documents\n",
      "Upserting 2100 documents\n",
      "Upserting 2200 documents\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_size = 100  # Adjust this batch size based on your rate limit\n",
    "delay = 70  # Delay in seconds between batches\n",
    "\n",
    "for i in range(0, len(splits), batch_size):\n",
    "    batch = splits[i:i+batch_size]\n",
    "    uuids = [str(uuid4()) for _ in range(len(batch))]\n",
    "    print(f\"Upserting {i} documents\")\n",
    "    # try:\n",
    "    response = vector_store_ellipsis.add_documents(documents=batch, ids=uuids)\n",
    "    #     print(f\"Response: {response}\")\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    time.sleep(delay)  # Delay to prevent hitting rate limits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RAG with Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the user's question. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "------\n",
    "<ctx>\n",
    "{context}\n",
    "</ctx>\n",
    "------\n",
    "<hs>\n",
    "{history}\n",
    "</hs>\n",
    "------\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature = 0.6, openai_api_key = os.getenv(\"API_KEY\"), openai_api_base = os.getenv(\"ENDPOINT\"), model_name=\"gpt-35-turbo\", engine=\"Voicetask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store_ellipsis.as_retriever(search_kwargs={'k': 5,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": ConversationBufferWindowMemory(\n",
    "            k = 10,\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\"),\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "------\n",
      "<ctx>\n",
      "worsensAssess likelihood for cervical cancer\n",
      " ■Assess signs and symptoms (i.e. history, intensity, duration, progression)\n",
      " ■Identify relevant risk factors: age (30 years old and above)\n",
      " ■Speculum examination\n",
      " ■Differential diagnosis: abortion in pre-menopausal women, infections (e.g. Chlamydiae, \n",
      "gonococcal, etc.), genital ulcers, cervical inflammation, uterine polyps, dysfunctional uterus \n",
      "hemorrhage, endometrial or vaginal cancerWomen who present the following persistent and unexplained signs and symptoms should seek consultation at a PHC:\n",
      "a) Abnormal vaginal bleeding (i.e. after coitus, between menstrual periods, post menopause)\n",
      "b) Foul-smelling discharge\n",
      "c) Pain during vaginal intercourse\n",
      "d) Any of the above associated with palpable abdominal mass with persistent low back or \n",
      "abdominal pain\n",
      "Reference: Guidelines for referral of suspected breast and cervical cancer at primary \n",
      "health care in low resource settings, World Health Organization, 2013\n",
      "\n",
      "important to undergo further investigation because, in the event that \n",
      "cancer is diagnosed, the treatment outcome is much better when the \n",
      "cancer is detected early and treated properly. This is particularly \n",
      "relevant in women 30 years and above who are at higher risk of \n",
      "developing cervical cancer.\n",
      "7 Abnormal vaginal bleeding includes occurrences after coitus, between menstrual \n",
      "periods, or after menopause.\n",
      "8 For further information consult the following WHO guidelines: WHO Guidelines \n",
      "for the Management of Sexually Transmitted Infections (WHO 2003) and Managing \n",
      "Complications in Pregnancy and Childbirth: a guide for midwives and doctors (WHO \n",
      "2000, reprinted 2007).\n",
      "\n",
      "-\n",
      "cal cancer in earlier stages when treatment is more effective. It is \n",
      "also important to keep in mind that even in well-established cervical \n",
      "screening programmes there are women who will present with an \n",
      "invasive cancer that can be detected early through warning signs and \n",
      "symptoms. These are mainly women who do not attend screening, as \n",
      "well as women who, although regularly screened, may have a false \n",
      "negative result or develop an interval cancer.\n",
      "\n",
      "in C4GEP, organized population-based screening of women over 30 \n",
      "years of age is the key early detection strategy that can reduce the incidence and mortality of invasive cervical cancer in a significant \n",
      "way. However, in those settings where cervical cancer screening is not \n",
      "yet available or is in its initial stages of development, prompt referral based on symptoms and signs is the only other method of diagnosing \n",
      "cervical cancer in earlier stages when treatment is more effective. It is \n",
      "also important to keep in mind that even in well-established cervical \n",
      "screening programmes there are women who will present with an \n",
      "invasive cancer that can be detected early through warning signs and \n",
      "symptoms. These are mainly women who do not receive screening, \n",
      "as well as women who, although regularly screened, may have a false \n",
      "negative result or develop an interval cancer.\n",
      "\n",
      "5.5Recommendations for preventing cancer\n",
      "5.5.1 Background\n",
      "Cancer is caused by a variety of identified and unidentified factors. The\n",
      "most important established cause of cancer is tobacco smoking. Otherimportant determinants of cancer risk include diet, alcohol and physical\n",
      "activity, infections, hormonal factors and radiation. The relative\n",
      "importance of cancers as a cause of death is increasing, mostly because\n",
      "oftheincreasingproportionofpeoplewhoareold,andalsoinpartbecause\n",
      "of reductions in mortality from some other causes, especially infectious\n",
      "diseases.Theincidenceofcancersofthelung,colonandrectum,breastand\n",
      "prostate generally increases in parallel with economic development, while\n",
      "the incidence of stomach cancer usually declines with development.\n",
      "5.5.2 Trends\n",
      "Cancer is now a major cause of mortality throughout the world and, in the\n",
      "developed world, is generally exceeded only by cardiovascular diseases.An estimated 10 million new cases and over 6 million deaths from cancer\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "\n",
      "</hs>\n",
      "------\n",
      "What are the major causees of cervical cancer??\n",
      "Answer:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "According to the context, the most important established cause of cancer is tobacco smoking. However, it is not specified if this is the major cause of cervical cancer. The context does mention that identifying relevant risk factors such as age (30 years old and above) and undergoing cervical screening are important for early detection and treatment. It is recommended to seek consultation if experiencing persistent and unexplained signs and symptoms such as abnormal vaginal bleeding, foul-smelling discharge, and pain during vaginal intercourse.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the major causees of cervical cancer??\"\n",
    "# response = qa_stuff.run(query)\n",
    "print(qa_stuff.run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ellipsis-Care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
