{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add OpenAI library\n",
    "import openai\n",
    "\n",
    "# Get Configuration Settings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.28.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting PDF content with Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_contents_from_doc(files, dir=\"../extracted_data\"):\n",
    "    \"\"\"\n",
    "    Azure Document Intelligence\n",
    "    Args: \n",
    "        files (uploaded by the user): List of uploaded files to process.\n",
    "        temp_dir (str): Directory path to store the extracted contents.\n",
    "    \n",
    "    Returns: \n",
    "        List of file paths where the extracted content is stored.\n",
    "    \"\"\"\n",
    "    # Constants for Azure Document Intelligence\n",
    "    DI_ENDPOINT = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "    DOCUMENT_INTELLIGENCE_KEY = os.getenv('DOCUMENT_INTELLIGENCE_SUBSCRIPTION_KEY')\n",
    "\n",
    "    if not DI_ENDPOINT or not DOCUMENT_INTELLIGENCE_KEY:\n",
    "        return []\n",
    "\n",
    "    document_intelligence_client = DocumentAnalysisClient(\n",
    "        endpoint=DI_ENDPOINT,\n",
    "        credential=AzureKeyCredential(DOCUMENT_INTELLIGENCE_KEY)\n",
    "    )\n",
    "\n",
    "    # Ensure the temporary directory exists\n",
    "    # os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "    extracted_file_paths = []\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Read file content\n",
    "            file_content = file.read()\n",
    "                \n",
    "            # Perform content extraction using Azure's \"prebuilt-read\" model\n",
    "            extract = document_intelligence_client.begin_analyze_document(\"prebuilt-read\", file_content)\n",
    "            result = extract.result()\n",
    "\n",
    "            # Extract content from each page\n",
    "            extracted_content = \"\"\n",
    "            for page in result.pages:\n",
    "                for line in page.lines:\n",
    "                    extracted_content += line.content + \"\\n\"\n",
    "            \n",
    "            # Secure the filename and define a path for saving extracted content\n",
    "            # filename = secure_filename(file.name)\n",
    "            filename = file.name\n",
    "            base, ext = os.path.splitext(filename)\n",
    "            # print(\"base: \", base)\n",
    "            # print(\"ext: \", ext)\n",
    "            extracted_filename = f\"{base.split('/')[-1]}_extracted.txt\"  # Save as .txt for easier reading\n",
    "            file_path = os.path.join(dir, extracted_filename)\n",
    "\n",
    "            # Save the extracted content to a file\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(extracted_content)\n",
    "            \n",
    "            extracted_file_paths.append(file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue  # Proceed with the next file in case of an error\n",
    "\n",
    "    return extracted_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../extracted_data/Action Framework for the Prevention and Control of Chronic Disease_extracted.txt\n",
      "../extracted_data/WHO_Package of Essential Noncommunicable (PEN) disease interventions for primary health care in low-resou_extracted.txt\n",
      "../extracted_data/WHO_DIET, NUTRITION AND THE PREVENTION OF CHRONIC DISEASES_extracted.txt\n",
      "../extracted_data/WHO model list of essential medicines_extracted.txt\n",
      "../extracted_data/GUIDELINES FOR THE PREVENTION, CARE AND TREATMENT OF PERSONS WITH CHRONIC HEPATITIS B INFECTION_extracted.txt\n"
     ]
    }
   ],
   "source": [
    "pdf_folder_path =  \"../data\"\n",
    "for file in os.listdir(pdf_folder_path):\n",
    "    if file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(pdf_folder_path, file)\n",
    "        path1 = extract_contents_from_doc([open(pdf_path, \"rb\")])\n",
    "        print(path1[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI API using Azure OpenAI\n",
    "openai.api_key = os.getenv(\"API_KEY\")\n",
    "openai.api_base = os.getenv(\"ENDPOINT\")\n",
    "openai.api_type = \"azure\"  # Necessary for using the OpenAI library with Azure OpenAI\n",
    "openai.api_version = \"2024-02-01\"  # Latest / target version of the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings, AzureOpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Settings\n",
    "model_deployment = \"text-embedding-ada-002\"\n",
    "# SDK calls this \"engine\", but naming it \"deployment_name\" for clarity\n",
    "\n",
    "model_name = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/Ellipsis-Care/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "openai_embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "    openai_api_version = os.getenv(\"OPENAI_API_VERSION\"), openai_api_key = os.getenv(\"API_KEY\"),\n",
    "    openai_api_base = os.getenv(\"ENDPOINT\"), openai_api_type = \"azure\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store_ellipsis = Chroma(\n",
    "    collection_name=\"Ellipsis-Care-Docs\",\n",
    "    embedding_function=openai_embeddings,\n",
    "    persist_directory=\"../Ellipsis-Care-Chroma-Vector-DB\",  # Where to save data locally, remove if not neccesary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "def upsert_pdf_content(file:str) -> Exception:\n",
    "        \"\"\"\n",
    "        This method is responsible for upserting PDF content.\n",
    "        It loads the PDF file, splits the content into chunks, and then upserts the chunks into VecDB.\n",
    "        \"\"\"\n",
    "        loader = PyPDFLoader(file)\n",
    "        data = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=200, separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"])\n",
    "        docs = text_splitter.split_documents(data)\n",
    "        # print(docs)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "\n",
    "def load_and_process_txts(txt_folder_path):\n",
    "        \"\"\"\n",
    "        This method is responsible for upserting TXT content.\n",
    "        It loads the TXT file, splits the content into chunks, and then upserts the chunks into VecDB.\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for file in os.listdir(txt_folder_path):\n",
    "            if file.endswith(\".txt\"):\n",
    "                txt_path = os.path.join(txt_folder_path, file)\n",
    "                loader = TextLoader(txt_path)\n",
    "                documents.extend(loader.load())\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300, separators=[\"\\n\", \" \", \"?\", \".\", \"!\"])\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_folder_path =  \"../extracted_data\"\n",
    "splits = load_and_process_txts(txt_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2096"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U/L for women, although local laboratory normal ranges should be\n",
      "applied. Persistently abnormal or normal may be defined as three\n",
      "ALT determinations above or below the upper limit of normal,\n",
      "made at unspecified intervals during a 6-12-month period or\n",
      "predefined intervals during a 12-month period.\n",
      "ASSESSMENT OF LIVER FIBROSIS BY NON-INVASIVE TESTS\n",
      "APRI\n",
      "FIB-4\n",
      "FibroTest (FibroSure)\n",
      "Commercial biomarker test that uses the results of six blood\n",
      "markers to estimate hepatic fibrosis\n",
      "Transient elastography\n",
      "(FibroScan)\n",
      "Aspartate aminotransferase (AST)-to-platelet ratio index (APRI) is\n",
      "a simple index for estimating hepatic fibrosis based on a formula\n",
      "derived from AST and platelet concentrations.\n",
      "A formula for calculating the APRI is given: APRI = * (AST/ULN) x\n",
      "100) / platelet count (109/L). An online calculator can be found at:\n",
      "http://www.hepatitisc.uw.edu/page/clinical-calculators/apri\n",
      "A simple index for estimating hepatic fibrosis based on a calculation\n"
     ]
    }
   ],
   "source": [
    "print(splits[30].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../extracted_data/GUIDELINES FOR THE PREVENTION, CARE AND TREATMENT OF PERSONS WITH CHRONIC HEPATITIS B INFECTION_extracted.txt'}, page_content='U/L for women, although local laboratory normal ranges should be\\napplied. Persistently abnormal or normal may be defined as three\\nALT determinations above or below the upper limit of normal,\\nmade at unspecified intervals during a 6-12-month period or\\npredefined intervals during a 12-month period.\\nASSESSMENT OF LIVER FIBROSIS BY NON-INVASIVE TESTS\\nAPRI\\nFIB-4\\nFibroTest (FibroSure)\\nCommercial biomarker test that uses the results of six blood\\nmarkers to estimate hepatic fibrosis\\nTransient elastography\\n(FibroScan)\\nAspartate aminotransferase (AST)-to-platelet ratio index (APRI) is\\na simple index for estimating hepatic fibrosis based on a formula\\nderived from AST and platelet concentrations.\\nA formula for calculating the APRI is given: APRI = * (AST/ULN) x\\n100) / platelet count (109/L). An online calculator can be found at:\\nhttp://www.hepatitisc.uw.edu/page/clinical-calculators/apri\\nA simple index for estimating hepatic fibrosis based on a calculation')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     print(splits[i])\n",
    "#     print(i)\n",
    "#     print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuids = [str(uuid4()) for _ in range(len(splits))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2096"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from uuid import uuid4\n",
    "# import time\n",
    "\n",
    "# delay = 70  # Delay in seconds between batches\n",
    "\n",
    "# for file in os.listdir(pdf_folder_path):\n",
    "#     if file.endswith(\".pdf\"):\n",
    "#         pdf_path = os.path.join(pdf_folder_path, file)\n",
    "#         docs = upsert_pdf_content(pdf_path)\n",
    "#         for chunk in docs:\n",
    "#             doc_id = str(uuid4())\n",
    "#             vector_store_ellipsis.add_documents(documents=[chunk], ids=[doc_id])\n",
    "#             time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting 0 documents\n",
      "Upserting 100 documents\n",
      "Upserting 200 documents\n",
      "Upserting 300 documents\n",
      "Upserting 400 documents\n",
      "Upserting 500 documents\n",
      "Upserting 600 documents\n",
      "Upserting 700 documents\n",
      "Upserting 800 documents\n",
      "Upserting 900 documents\n",
      "Upserting 1000 documents\n",
      "Upserting 1100 documents\n",
      "Upserting 1200 documents\n",
      "Upserting 1300 documents\n",
      "Upserting 1400 documents\n",
      "Upserting 1500 documents\n",
      "Upserting 1600 documents\n",
      "Upserting 1700 documents\n",
      "Upserting 1800 documents\n",
      "Upserting 1900 documents\n",
      "Upserting 2000 documents\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from uuid import uuid4\n",
    "\n",
    "batch_size = 100  # Adjust this batch size based on your rate limit\n",
    "delay = 70  # Delay in seconds between batches\n",
    "\n",
    "for i in range(0, len(splits), batch_size):\n",
    "    batch = splits[i:i+batch_size]\n",
    "    uuids = [str(uuid4()) for _ in range(len(batch))]\n",
    "    print(f\"Upserting {i} documents\")\n",
    "    # try:\n",
    "    response = vector_store_ellipsis.add_documents(documents=batch, ids=uuids)\n",
    "    #     print(f\"Response: {response}\")\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n",
    "    time.sleep(delay)  # Delay to prevent hitting rate limits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing RAG with Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory, ConversationBufferWindowMemory\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the user's question. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "------\n",
    "<ctx>\n",
    "{context}\n",
    "</ctx>\n",
    "------\n",
    "<hs>\n",
    "{history}\n",
    "</hs>\n",
    "------\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/Ellipsis-Care/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature = 0.6, openai_api_key = os.getenv(\"API_KEY\"), openai_api_base = os.getenv(\"ENDPOINT\"), model_name=\"gpt-35-turbo\", engine=\"Voicetask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store_ellipsis.as_retriever(search_kwargs={'k': 5,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": ConversationBufferWindowMemory(\n",
    "            k = 10,\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\"),\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/Ellipsis-Care/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "------\n",
      "<ctx>\n",
      "signs of cervical cancer (Shapley et al., 2006; Sarkar et al., 2010;\n",
      "Ikechebelu et al., 2010). These signs may be associated with early\n",
      "stages of invasive cervical cancer, particularly in women above the\n",
      "age of 30 years. However, abnormal vaginal bleeding in sexually active\n",
      "women is more frequently caused by abortion (in pre-menopausal\n",
      "women) and benign conditions such as cervical infections (including\n",
      "gonorrhoea and chlamydiae) ulceration due to cervical inflammatory\n",
      "disease, uterine polyps, and dysfunctional uterine bleeding due to\n",
      "hormonal imbalance. Similarly, persistent, foul smelling discharge\n",
      "may be associated with other conditions such as bacterial vaginosis,\n",
      "trichomoniasis, and vaginal candidiasis. Moreover, abnormal vaginal\n",
      "bleeding may sometimes be caused by other malignant conditions\n",
      "such as endometrial or vaginal cancer.\n",
      "Some women with cervical cancer may experience pain during vagi-\n",
      "nal intercourse The association of a palpable abdominal mass with\n",
      "\n",
      "1 Abnormal vaginal bleeding includes occurrences after coitus, between menstrual\n",
      "periods, or after menopause.\n",
      "2 For further information, consult the following WHO guidelines: WHO Guidelines\n",
      "for the Management of Sexually Transmitted Infections (WHO 2003) and Managing\n",
      "Complications in Pregnancy and Childbirth: a guide for midwives and doctors (WHO\n",
      "2000).\n",
      "34\n",
      "Guidelines for referral of suspected breast and cervical cancer at primary health care in low-resource settings\n",
      "diagnosed, the treatment outcome is much better when the cancer\n",
      "is detected early and treated properly. This is particularly relevant\n",
      "in women 30 years and older who are at higher risk of developing\n",
      "cervical cancer.\n",
      "Women with any signs or symptoms associated with advanced cervi-\n",
      "cal cancer (such as severe abdominal pain, abdominal distension,\n",
      "severe back pain, neck swelling, or symptoms of urethral and rectal\n",
      "fistula) should also be referred to a specialized centre for confirma-\n",
      "tion diagnosis and appropriate care.\n",
      "35\n",
      "\n",
      "cal cancer in earlier stages, the following are strong recommendations\n",
      "for referral of women with possible cervical cancer:\n",
      "Women who report any gynaecological sign or symptom suspicious\n",
      "of early cervical cancer (such as abnormal vaginal bleeding,7 or\n",
      "persistent, foul-smelling discharge, or pain during vaginal inter-\n",
      "course) should, where possible, undergo a speculum examination.\n",
      "The following important issues should be taken into consideration:\n",
      "Â· In women with abnormal vaginal bleeding, with persistent, foul-\n",
      "smelling discharge, or experiencing pain during vaginal inter-\n",
      "course, the presence of a cervical growth or ulceration should\n",
      "prompt immediate referral for diagnostic confirmation and man-\n",
      "agement without manipulation because of the significant risk of\n",
      "bleeding, which may be difficult to control.\n",
      "Women with abnormal vaginal bleeding, with persistent, foul-smell-\n",
      "ing discharge, or experiencing pain during vaginal intercourse,\n",
      "\n",
      "The GDG concluded that the existence or absence of risk factors for\n",
      "breast and cervical cancer, in general, do not affect the decision of\n",
      "referral. For an important proportion of women presenting with\n",
      "signs and symptoms suspicious of breast or cervical cancer, specific\n",
      "risk factors may not be identified. Moreover, clinical prediction rules\n",
      "based on combinations of signs, symptoms, and risk factors are not\n",
      "more likely to be useful for deciding on referral than clinical signs\n",
      "and symptoms alone.\n",
      "In view that, in general, risk factors (see Annex II) do not influence\n",
      "the referral of breast or cervical cancer at PHC, GDG decided to not\n",
      "include risk factors in the formulation of the recommendations,\n",
      "except age for both cancers and relevant risk factors for breast can-\n",
      "cer (family history, former breast cancer, therapeutic chest irradia-\n",
      "tion) in women under 30 years of age presenting with a breast lump.\n",
      "44\n",
      "\n",
      "The objective of this guideline is to assist primary care practitioners\n",
      "in the early identification of patients with signs and symptoms sus-\n",
      "picious of breast and cervical cancer so they can be referred to the\n",
      "next level of care for diagnosis and subsequent treatment, if cancer\n",
      "is confirmed .\n",
      "The initial scope of the original cancer guidelines, as agreed by\n",
      "the Guideline Development Group (GDG), included breast, cervical,\n",
      "oral, prostate, and colorectal cancer in view of their high incidence\n",
      "in low- and middle-income countries and because they are particu-\n",
      "larly amenable to early detection and effective treatment. A review\n",
      "of systematic reviews of signs, symptoms, and risk factors for each\n",
      "of the cancer sites was performed and discussed at the first meeting\n",
      "of the GDG in February 2011. In view of the enormous amount of\n",
      "work that the review of five cancer sites involved, the GDG advised\n",
      "to focus initially on breast and cervical cancer, and subsequently on\n",
      "the remaining cancer sites.\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "\n",
      "</hs>\n",
      "------\n",
      "What are the major causees of cervical cancer??\n",
      "Answer:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "According to the context provided, the signs of cervical cancer may be associated with early stages of invasive cervical cancer, particularly in women above the age of 30 years. However, abnormal vaginal bleeding in sexually active women is more frequently caused by abortion (in pre-menopausal women) and benign conditions such as cervical infections (including gonorrhoea and chlamydiae), ulceration due to cervical inflammatory disease, uterine polyps, and dysfunctional uterine bleeding due to hormonal imbalance. Similarly, persistent, foul-smelling discharge may be associated with other conditions such as bacterial vaginosis, trichomoniasis, and vaginal candidiasis. Moreover, abnormal vaginal bleeding may sometimes be caused by other malignant conditions such as endometrial or vaginal cancer. Therefore, these are the major causes of abnormal vaginal bleeding and discharge, but it is important to consult a healthcare provider for a proper diagnosis.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the major causees of cervical cancer??\"\n",
    "# response = qa_stuff.run(query)\n",
    "print(qa_stuff.run(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ellipsis-Care",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
